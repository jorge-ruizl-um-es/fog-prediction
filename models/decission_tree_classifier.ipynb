{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12a9564",
   "metadata": {},
   "source": [
    "# Entrenamiento y prueba de un modelo clasificador basado en árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a848aa",
   "metadata": {},
   "source": [
    "Observando el dataset que manejamos, percibimos que tiene pocos datos y, para el problema que queremos resolver, necesitamos un clasificador binario dado que el *target* es una variable discreta que toma los valores \"SI\" o \"NO\". Para ello, podemos pensar en una primera aproximación a través de árboles de decisión, cuya interpretación es muy intuitiva y tienen alta explicabilidad. \n",
    "\n",
    "El dilema que encontramos aquí es que este tipo de modelos tienden a sobreajustar los datos de entrenamiento. Debido a la naturaleza del problema y a los escasos datos en general de los que partimos, pese a evaluar el rendimiento del modelo mediante división en *training* y *test*, quizás los resultados no sean concluyentes. Estudiaremos si podemos recurrir a validación cruzada y si esta técnica mejora la evaluación de resultados. \n",
    "\n",
    "Se ha elegido un árbol de decisión por encima de modelos más complejos como *Random Forest* debido a que tenemos pocos datos, tanto de entrenamiento como de test, y es un problema de clasificación bastante sencillo, con no muchas variables. Aún así, también probaremos con modelos algo más complejos como redes neuronales no muy densas. \n",
    "\n",
    "Una vez se haya entrenado el modelo, se pondrá en práctica con 4 instancias de datos cuyas etiquetas desconocemos, ya que son días que, a día de hoy (25 de julio de 2025), no se han desarrollado aún. La utilidad del modelo será poder predecir la niebla que habrá durante estos días en base a las previsiones de las que disponemos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18055a54",
   "metadata": {},
   "source": [
    "## Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ab774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b56b6",
   "metadata": {},
   "source": [
    "## Importación de datos y tratamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6512023",
   "metadata": {},
   "source": [
    "Primero, descargamos los datos de los CSV's generados con las llamadas a la API de la AEMET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e869156",
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla = 123\n",
    "np.random.seed(semilla)\n",
    "base_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "\n",
    "datos = pd.read_csv(os.path.join(base_dir, \"data\", \"processed\", \"data.csv\"), sep=\";\")\n",
    "datos_sin_etiquetar = pd.read_csv(os.path.join(base_dir, \"data\", \"processed\", \"data_sin_etiquetar.csv\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c2eb0",
   "metadata": {},
   "source": [
    "Una vez cargados, debemos convertir las variables cualitativas a *dummies* para asegurar un correcto entrenamiento y uso del modelo. Lo haremos con la función `get_dummies` de `pandas`.\n",
    "\n",
    "Primero, extraemos las variable categóricas de los dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8517a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha', 'altonubes', 'nubosidad', 'lluvia', 'viento', 'SUBIR'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricas = datos.select_dtypes(include= [\"object\", \"category\"]).columns\n",
    "categoricas_sin_etiquetar = datos_sin_etiquetar.select_dtypes(include= [\"object\", \"category\"]).columns\n",
    "categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950e30c",
   "metadata": {},
   "source": [
    "No vamos a tener en cuenta las variables \"fecha\", dado que esta es el índice (clave primaria que identifica cada dato); ni \"SUBIR\", dado que es el target a predecir y no haría falta transformarlo. De hecho, la variable \"fecha\" podrá eliminarse por completo del dataset, dado que no influye a la hora de realizar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fb309e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['altonubes', 'nubosidad', 'lluvia', 'viento'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricas = categoricas.delete([0, 5])\n",
    "datos.drop(\"fecha\", axis=1, inplace=True)\n",
    "categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617daf73",
   "metadata": {},
   "source": [
    "De las \"sin etiquetar\", vamos a eliminar únicamente la fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46612089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['altonubes', 'nubosidad', 'lluvia', 'viento'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_sin_etiquetar.drop(\"fecha\", axis=1, inplace=True)\n",
    "categoricas_sin_etiquetar = categoricas_sin_etiquetar.delete(0)\n",
    "categoricas_sin_etiquetar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8df91b",
   "metadata": {},
   "source": [
    "Transformamos a dummies y eliminamos las variables originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cbaaac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>velmedia</th>\n",
       "      <th>hrMedia</th>\n",
       "      <th>hrMax</th>\n",
       "      <th>hrMin</th>\n",
       "      <th>SUBIR</th>\n",
       "      <th>altonubes_mid</th>\n",
       "      <th>altonubes_nan</th>\n",
       "      <th>nubosidad_escasa</th>\n",
       "      <th>nubosidad_media</th>\n",
       "      <th>nubosidad_nan</th>\n",
       "      <th>lluvia_no</th>\n",
       "      <th>lluvia_posible</th>\n",
       "      <th>lluvia_nan</th>\n",
       "      <th>viento_fuerte</th>\n",
       "      <th>viento_moderado</th>\n",
       "      <th>viento_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>26.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>SI</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SI</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prec  tmin  tmax  velmedia  hrMedia  hrMax  hrMin SUBIR  altonubes_mid  \\\n",
       "0   0.0  11.9  20.4       1.4     99.0  100.0   61.0    NO          False   \n",
       "1   2.0  11.7  25.0       2.5     64.0  100.0   40.0    NO          False   \n",
       "2  23.8  13.7  26.6       5.6     54.0   94.0   34.0    SI           True   \n",
       "3   2.0  11.5  19.9       3.6     86.0  100.0   50.0    SI          False   \n",
       "4   0.0  11.4  18.2       1.4     95.0  100.0   80.0    NO          False   \n",
       "\n",
       "   altonubes_nan  nubosidad_escasa  nubosidad_media  nubosidad_nan  lluvia_no  \\\n",
       "0          False             False            False          False      False   \n",
       "1           True             False            False           True      False   \n",
       "2          False              True            False          False      False   \n",
       "3           True             False            False          False      False   \n",
       "4          False              True            False          False       True   \n",
       "\n",
       "   lluvia_posible  lluvia_nan  viento_fuerte  viento_moderado  viento_nan  \n",
       "0            True       False          False             True       False  \n",
       "1           False        True          False            False        True  \n",
       "2           False       False           True            False       False  \n",
       "3           False       False          False             True       False  \n",
       "4           False       False          False            False       False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricas_dummies = pd.get_dummies(datos[categoricas], drop_first = True, dummy_na = True)\n",
    "categoricas_sin_etiquetar_dummies = pd.get_dummies(datos_sin_etiquetar[categoricas_sin_etiquetar], drop_first = True, dummy_na = True)\n",
    "\n",
    "datos.drop(categoricas, axis = 1, inplace = True)   # inplace para que se elimine sobre el dataset\n",
    "datos_sin_etiquetar.drop(categoricas_sin_etiquetar, axis=1, inplace=True)\n",
    "\n",
    "# Tras eliminar los atributos originales, concatenamos los nuevos atributos creados para las variables categóricas.\n",
    "datos = pd.concat([datos, categoricas_dummies], axis = 1)\n",
    "datos_sin_etiquetar = pd.concat([datos_sin_etiquetar, categoricas_sin_etiquetar_dummies], axis = 1)\n",
    "\n",
    "# Mostramos cómo queda tras este proceso\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65fc6f",
   "metadata": {},
   "source": [
    "## Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e911c",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, vamos a proceder con el entrenamiento del modelo. Para ello, usaremos los datos etiquetados de los que disponemos, que conforman un conjunto extremadamente pequeño. Debido a esto, no conviene realizar un *train-test split* al uso, sino que optamos por una validación cruzada con *Leave-One-Out*. Esta es la mejor forma de lidiar con datasets pequeños, dado que cada instancia se usará una vez como test, y el resto como entrenamiento. Es una técnica costosa computacionalmente, pero ante la escasa cantidad de datos, no será un inconveniente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
